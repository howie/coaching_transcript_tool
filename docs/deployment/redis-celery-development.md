# Redis & Celery Development Environment Setup

This document explains how to set up Redis in Docker and run Celery workers for the Coaching Transcript Tool development environment.

## Overview

In the development environment:
- **Redis** runs in a Docker container as the message broker
- **Celery workers** run on the host machine for easier debugging
- **API server** connects to Redis for task queuing
- **Google STT** processes audio files asynchronously via Celery

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Server    â”‚    â”‚  Redis (Docker)  â”‚    â”‚  Celery Worker  â”‚
â”‚  (Host: 8000)   â”‚â—„â”€â”€â–ºâ”‚  (Port: 6379)    â”‚â—„â”€â”€â–ºâ”‚  (Host Process) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚    â”‚   Task Queue     â”‚    â”‚   Google STT    â”‚
â”‚   (Database)    â”‚    â”‚  (Redis Lists)   â”‚    â”‚   API Service   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Prerequisites

- Docker installed and running
- Python 3.11+ with project dependencies installed
- PostgreSQL database running (local or cloud)
- Google Cloud service account credentials

## Step 1: Start Redis with Docker

### Option A: Using Docker Compose (Recommended)

Update `docker-compose.yml` to include Redis:

```yaml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --requirepass redis_pass_dev
    volumes:
      - redis_data:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

volumes:
  redis_data:
```

Start Redis:
```bash
docker-compose up -d redis
```

### Option B: Using Docker directly

```bash
# Start Redis container
docker run -d \
  --name coaching-redis \
  -p 6379:6379 \
  --restart unless-stopped \
  redis:7-alpine \
  redis-server --requirepass redis_pass_dev

# Verify Redis is running
docker logs coaching-redis
```

### Verify Redis Connection

```bash
# Test Redis connection
redis-cli -h localhost -p 6379 -a redis_pass_dev ping
# Should return: PONG

# Or using Docker exec
docker exec coaching-redis redis-cli -a redis_pass_dev ping
```

## Step 2: Configure Environment Variables

Ensure these variables are set in your `.env` file:

```bash
# Redis Configuration
REDIS_URL=redis://:redis_pass_dev@localhost:6379/0
CELERY_BROKER_URL=redis://:redis_pass_dev@localhost:6379/0
CELERY_RESULT_BACKEND=redis://:redis_pass_dev@localhost:6379/0

# Database
DATABASE_URL=postgresql://coach_user:coach_pass_dev@localhost:5432/coaching_assistant_dev

# Google STT
GOOGLE_APPLICATION_CREDENTIALS_JSON=<base64_encoded_service_account_json>
GOOGLE_PROJECT_ID=your-project-id
```

## Step 3: Start Celery Worker

Open a new terminal and start the Celery worker:

```bash
# Navigate to project root
cd /path/to/coaching_transcript_tool

# Start Celery worker with development settings
celery -A coaching_assistant.core.celery_app worker \
  --loglevel=info \
  --concurrency=2 \
  --pool=threads

# For more verbose logging
celery -A coaching_assistant.core.celery_app worker \
  --loglevel=debug \
  --concurrency=1 \
  --pool=threads
```

Expected output:
```
 -------------- celery@hostname v5.3.x
---- **** -----
--- * ***  * --
-- * - **** -
- ** ----------
- ** ----------

[config]
.> app:         coaching_assistant.core.celery_app:0x...
.> transport:   redis://:**@localhost:6379/0
.> results:     redis://:**@localhost:6379/0
.> concurrency: 2 (threads)
.> task events: OFF (enable -E to monitor tasks in Flower)
.> queues:      celery (exchange=celery, routing_key=celery)

[tasks]
  . coaching_assistant.tasks.transcription_tasks.transcribe_audio
```

## Step 4: Start API Server

In another terminal, start the API server:

```bash
# Make sure dependencies are installed
make dev-setup

# Start API server
make run-api
```

## Step 5: Test the Setup

### Verify Celery Connection

```bash
# Run the Celery status check script
python3 apps/web/check_celery_status.py
```

Expected output:
```
ğŸ“‹ Registered Celery Tasks:
  - coaching_assistant.tasks.transcription_tasks.transcribe_audio

ğŸ”„ Active Tasks:
  Worker: celery@hostname
```

### Test Transcription Flow

```bash
# Run the transcription test script
python3 apps/web/test_transcription_flow.py
```

This script will:
1. Check Celery connection
2. Look for pending transcription sessions
3. Allow you to trigger a test transcription
4. Monitor task progress

## How Celery Interacts with Redis

### Task Queuing Process

1. **API receives audio upload**:
   ```python
   # API creates session and queues transcription task
   task = transcribe_audio.delay(session_id, gcs_path, language)
   session.transcription_job_id = task.id
   ```

2. **Redis stores task data**:
   ```
   # Redis key structure
   celery-task-meta-<task_id>  # Task metadata and results
   celery                      # Default queue name (Redis list)
   ```

3. **Celery worker processes tasks**:
   ```python
   # Worker picks up task from Redis queue
   @celery_app.task
   def transcribe_audio(session_id, gcs_path, language):
       # Process audio with Google STT
       # Update database with progress
       # Return results
   ```

### Redis Data Structure

Redis uses these data structures for Celery:

```bash
# List tasks in queue (Redis list)
redis-cli -a redis_pass_dev LLEN celery

# Check task metadata (Redis hash)
redis-cli -a redis_pass_dev HGETALL celery-task-meta-<task_id>

# Monitor real-time commands
redis-cli -a redis_pass_dev MONITOR
```

### Task States

Celery tasks go through these states:
- `PENDING`: Task waiting in queue
- `STARTED`: Worker picked up task
- `PROGRESS`: Custom state for progress updates
- `SUCCESS`: Task completed successfully
- `FAILURE`: Task failed with error
- `RETRY`: Task failed but will be retried

## Monitoring & Debugging

### View Celery Logs

```bash
# Celery worker logs show task execution
# Look for these log messages:
# - "Task transcribe_audio[task_id] received"
# - "Starting transcription for session <id>"
# - "Google STT client initialized"
# - "Transcription completed for session <id>"
```

### Monitor Redis Activity

```bash
# Real-time Redis command monitoring
redis-cli -a redis_pass_dev MONITOR

# Check Redis memory usage
redis-cli -a redis_pass_dev INFO memory

# List all keys
redis-cli -a redis_pass_dev KEYS '*'
```

### Database Status Tracking

```sql
-- Check recent sessions and their processing status
SELECT 
    s.id,
    s.status,
    s.transcription_job_id,
    ps.progress,
    ps.message
FROM session s
LEFT JOIN processing_status ps ON s.id = ps.session_id
WHERE s.created_at > NOW() - INTERVAL '1 hour'
ORDER BY s.created_at DESC;
```

## Troubleshooting

### Common Issues

**1. "No Celery workers found"**
```bash
# Check if worker is running
ps aux | grep celery

# Restart worker
celery -A coaching_assistant.core.celery_app worker --loglevel=info
```

**2. "Redis connection refused"**
```bash
# Check if Redis container is running
docker ps | grep redis

# Start Redis container
docker-compose up -d redis
```

**3. "Google STT authentication failed"**
```bash
# Verify credentials are Base64 encoded
echo $GOOGLE_APPLICATION_CREDENTIALS_JSON | base64 -d | jq .

# Test STT service directly
python3 -c "
from coaching_assistant.services.google_stt import GoogleSTTService
stt = GoogleSTTService()
print('STT initialized successfully')
"
```

### Performance Tuning

For development, use these Celery settings:

```bash
# Low concurrency for debugging
celery worker --concurrency=1 --loglevel=debug

# Higher concurrency for testing
celery worker --concurrency=4 --loglevel=info

# Enable task events for monitoring
celery worker --loglevel=info -E
```

## Production Considerations

In production:
- Use Redis Cluster or managed Redis service
- Run multiple Celery workers across different machines
- Use proper process managers (systemd, supervisor)
- Enable task result persistence
- Set up monitoring with Flower or Celery monitoring tools

---

For more details, see:
- [Celery Documentation](https://docs.celeryq.dev/)
- [Redis Documentation](https://redis.io/docs/)
- [Google STT API Documentation](https://cloud.google.com/speech-to-text/docs)


###

ğŸ”§ Makefile æ–°å¢åŠŸèƒ½

  æ–°å¢ Celery æŒ‡ä»¤:
  - make run-celery - å•Ÿå‹• Celery worker (ä¸€èˆ¬æ¨¡å¼)
  - make run-celery-debug - å•Ÿå‹• Celery worker (é™¤éŒ¯æ¨¡å¼)

  æ–°å¢ Docker å»ºç½®æŒ‡ä»¤:
  - make docker-worker - å»ºç½®ä¸€èˆ¬ç”¨é€” Worker Docker image
  - make docker-worker-cloudrun - å»ºç½® GCP Cloud Run å°ˆç”¨ Worker image

  ğŸ“¦ ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²ç­–ç•¥

  Render.com

  æ–¹æ³• 1: åˆ†é›¢æœå‹™ (æ¨è–¦)
  - API Service: Web Service
  - Worker Service: Background Worker
  - ä½¿ç”¨ apps/worker/Dockerfile

  æ–¹æ³• 2: åˆä½µæœå‹™
  - å–®ä¸€æœå‹™åŒæ™‚åŸ·è¡Œ API + Worker
  - é©åˆå°è¦æ¨¡æ‡‰ç”¨

  GCP Cloud Run

  éœ€è¦ HTTP ç«¯é»ç”¨æ–¼å¥åº·æª¢æŸ¥
  - ä½¿ç”¨ apps/worker/Dockerfile.cloudrun
  - åŒ…å« health_server.py æä¾›å¥åº·æª¢æŸ¥ç«¯é»
  - æ”¯æ´ Cloud Run çš„è¦æ±‚

  ğŸ—ï¸ å»ºè­°æ¶æ§‹

  ç”Ÿç”¢ç’°å¢ƒæ¨è–¦åˆ†é›¢éƒ¨ç½²:
  Web Service (API) â†â†’ Managed Redis â†â†’ Worker Service (Celery)

  å„ªé»:
  - ç¨ç«‹æ“´å±•
  - æ•…éšœéš”é›¢
  - è³‡æºæœ€ä½³åŒ–
  - éƒ¨ç½²éˆæ´»æ€§

  å¿«é€Ÿå•Ÿå‹•:
  # é–‹ç™¼ç’°å¢ƒ
  make run-celery        # å•Ÿå‹• Celery worker
  make run-api          # å•Ÿå‹• API server

  # Docker å»ºç½®
  make docker-worker    # Render.com ç”¨
  make docker-worker-cloudrun  # GCP Cloud Run ç”¨

  æ‰€æœ‰éƒ¨ç½²ç´°ç¯€å’Œé…ç½®ç¯„ä¾‹éƒ½å·²è¨˜éŒ„åœ¨ docs/deployment/production-celery-deployment.md ä¸­ï¼