# AI åˆ†æåŠŸèƒ½æŠ€è¡“è¦æ ¼

## ğŸ¤– é …ç›® 7: AI åˆ†æ tab èˆ‡ LLM å°è«‡åŠŸèƒ½

æ­¤æ–‡æª”è©³ç´°è¦åŠƒæ–°å¢çš„ AI åˆ†æåŠŸèƒ½ï¼ŒåŒ…æ‹¬èˆ‡ LLM å°è«‡ã€æ‘˜è¦ç”Ÿæˆå’Œå›é¥‹ç”Ÿæˆç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚

---

## ğŸ“‹ åŠŸèƒ½æ¦‚è¦½

### æ ¸å¿ƒåŠŸèƒ½
1. **AI åˆ†æ Tab**: ç¨ç«‹çš„åˆ†æä»‹é¢
2. **ç”¢ç”Ÿæœƒè«‡æ‘˜è¦**: çµæ§‹åŒ–æ‘˜è¦ç”Ÿæˆ
3. **çµ¦äºˆæœƒè«‡å›é¥‹**: å­¸ç¿’å°å‘çš„å›é¥‹å»ºè­°
4. **LLM å°è«‡ä»‹é¢**: è‡ªç”±å°è©±åŠŸèƒ½ï¼ˆæœªä¾†æ“´å±•ï¼‰

### è¨­è¨ˆåŸå‰‡
- **å­¸ç¿’è¼”åŠ©å°å‘**: é¿å…è©•åˆ†å¼å›é¥‹
- **çµæ§‹åŒ–è¼¸å‡º**: æ˜“è®€æ˜“æ‡‚çš„åˆ†æçµæœ
- **å¤šèªè¨€æ”¯æ´**: ä¸­è‹±æ–‡åˆ†æ
- **æ€§èƒ½å„ªåŒ–**: åˆç†çš„å›æ‡‰æ™‚é–“

---

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹

### æ•´é«”æ¶æ§‹
```
å‰ç«¯ (Next.js)
â”œâ”€â”€ AI åˆ†æ Tab çµ„ä»¶
â”œâ”€â”€ æ‘˜è¦ç”Ÿæˆä»‹é¢
â”œâ”€â”€ å›é¥‹ç”Ÿæˆä»‹é¢
â””â”€â”€ å°è«‡ä»‹é¢ (æœªä¾†)

å¾Œç«¯ (FastAPI)
â”œâ”€â”€ AI åˆ†æ API ç«¯é»
â”œâ”€â”€ LLM æœå‹™å±¤
â”œâ”€â”€ Prompt ç®¡ç†
â””â”€â”€ çµæœè™•ç†

å¤–éƒ¨æœå‹™
â”œâ”€â”€ AssemblyAI LeMUR (ä¸»è¦)
â”œâ”€â”€ OpenAI GPT (å‚™ç”¨)
â””â”€â”€ å…¶ä»– LLM æœå‹™ (æœªä¾†)
```

---

## ğŸ¨ å‰ç«¯å¯¦ä½œè¦æ ¼

### çµ„ä»¶æ¶æ§‹
```
apps/web/components/ai-analysis/
â”œâ”€â”€ AIAnalysisTab.tsx          # ä¸»å®¹å™¨çµ„ä»¶
â”œâ”€â”€ SummaryGenerator.tsx       # æ‘˜è¦ç”Ÿæˆå™¨
â”œâ”€â”€ FeedbackGenerator.tsx      # å›é¥‹ç”Ÿæˆå™¨
â”œâ”€â”€ AnalysisResult.tsx         # çµæœé¡¯ç¤ºçµ„ä»¶
â”œâ”€â”€ LoadingState.tsx           # è¼‰å…¥ç‹€æ…‹
â””â”€â”€ ErrorState.tsx             # éŒ¯èª¤ç‹€æ…‹
```

### ä¸»è¦çµ„ä»¶å¯¦ä½œ

#### AIAnalysisTab.tsx
```typescript
import React, { useState } from 'react';
import { useTranscriptData } from '@/hooks/useTranscriptData';
import { SummaryGenerator } from './SummaryGenerator';
import { FeedbackGenerator } from './FeedbackGenerator';

interface AIAnalysisTabProps {
  sessionId: string;
}

export const AIAnalysisTab: React.FC<AIAnalysisTabProps> = ({ sessionId }) => {
  const { transcript, loading } = useTranscriptData(sessionId);
  const [activeAnalysis, setActiveAnalysis] = useState<string | null>(null);

  if (loading) {
    return <LoadingState />;
  }

  return (
    <div className="ai-analysis-tab">
      <div className="analysis-header">
        <h2>ğŸ¤– AI åˆ†æ</h2>
        <p>ä½¿ç”¨ AI æŠ€è¡“æ·±åº¦åˆ†ææ‚¨çš„æ•™ç·´æœƒè«‡</p>
      </div>

      <div className="analysis-tools">
        <div className="tool-grid">
          <SummaryGenerator 
            sessionId={sessionId}
            transcript={transcript}
            isActive={activeAnalysis === 'summary'}
            onActivate={() => setActiveAnalysis('summary')}
          />
          
          <FeedbackGenerator
            sessionId={sessionId}
            transcript={transcript}
            isActive={activeAnalysis === 'feedback'}
            onActivate={() => setActiveAnalysis('feedback')}
          />
        </div>
      </div>

      <div className="analysis-results">
        {/* åˆ†æçµæœé¡¯ç¤ºå€åŸŸ */}
      </div>
    </div>
  );
};
```

#### SummaryGenerator.tsx
```typescript
import React, { useState } from 'react';
import { useMutation } from '@tanstack/react-query';
import { generateSummary } from '@/lib/api/ai-analysis';
import { Button } from '@/components/ui/Button';
import { Card } from '@/components/ui/Card';

interface SummaryGeneratorProps {
  sessionId: string;
  transcript: TranscriptData;
  isActive: boolean;
  onActivate: () => void;
}

export const SummaryGenerator: React.FC<SummaryGeneratorProps> = ({
  sessionId,
  transcript,
  isActive,
  onActivate
}) => {
  const [summary, setSummary] = useState<SummaryResult | null>(null);

  const summaryMutation = useMutation({
    mutationFn: () => generateSummary({
      session_id: sessionId,
      content: transcript.fullText,
      language: 'zh-TW'
    }),
    onSuccess: (result) => {
      setSummary(result);
      onActivate();
    },
    onError: (error) => {
      console.error('Summary generation failed:', error);
    }
  });

  return (
    <Card className="analysis-tool">
      <div className="tool-header">
        <h3>ğŸ“‹ æœƒè«‡æ‘˜è¦</h3>
        <p>ç”Ÿæˆçµæ§‹åŒ–çš„æœƒè«‡æ‘˜è¦</p>
      </div>

      <div className="tool-content">
        <Button
          onClick={() => summaryMutation.mutate()}
          loading={summaryMutation.isPending}
          disabled={!transcript}
        >
          {summaryMutation.isPending ? 'ç”Ÿæˆä¸­...' : 'ç”¢ç”Ÿæœƒè«‡æ‘˜è¦'}
        </Button>

        {summary && (
          <div className="summary-result">
            <SummaryDisplay summary={summary} />
          </div>
        )}
      </div>
    </Card>
  );
};
```

#### FeedbackGenerator.tsx
```typescript
import React, { useState } from 'react';
import { useMutation } from '@tanstack/react-query';
import { generateFeedback } from '@/lib/api/ai-analysis';

interface FeedbackGeneratorProps {
  sessionId: string;
  transcript: TranscriptData;
  isActive: boolean;
  onActivate: () => void;
}

export const FeedbackGenerator: React.FC<FeedbackGeneratorProps> = ({
  sessionId,
  transcript,
  isActive,
  onActivate
}) => {
  const [feedback, setFeedback] = useState<FeedbackResult | null>(null);

  const feedbackMutation = useMutation({
    mutationFn: () => generateFeedback({
      session_id: sessionId,
      content: transcript.fullText,
      language: 'zh-TW',
      focus: 'learning_support' // å­¸ç¿’è¼”åŠ©å°å‘
    }),
    onSuccess: (result) => {
      setFeedback(result);
      onActivate();
    }
  });

  return (
    <Card className="analysis-tool">
      <div className="tool-header">
        <h3>ğŸ’¡ æœƒè«‡å›é¥‹</h3>
        <p>ç²å¾—å­¸ç¿’å°å‘çš„å»ºè­°å’Œæç¤º</p>
      </div>

      <div className="tool-content">
        <Button
          onClick={() => feedbackMutation.mutate()}
          loading={feedbackMutation.isPending}
          disabled={!transcript}
        >
          {feedbackMutation.isPending ? 'åˆ†æä¸­...' : 'çµ¦äºˆæœƒè«‡å›é¥‹'}
        </Button>

        {feedback && (
          <div className="feedback-result">
            <FeedbackDisplay feedback={feedback} />
          </div>
        )}
      </div>
    </Card>
  );
};
```

### æ¨£å¼è¨­è¨ˆ

#### ai-analysis.css
```css
.ai-analysis-tab {
  padding: 1.5rem;
  max-width: 1200px;
  margin: 0 auto;
}

.analysis-header {
  text-align: center;
  margin-bottom: 2rem;
}

.analysis-header h2 {
  font-size: 1.75rem;
  font-weight: 600;
  color: #1f2937;
  margin-bottom: 0.5rem;
}

.analysis-header p {
  color: #6b7280;
  font-size: 1rem;
}

.tool-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
  gap: 1.5rem;
  margin-bottom: 2rem;
}

.analysis-tool {
  border: 1px solid #e5e7eb;
  border-radius: 12px;
  padding: 1.5rem;
  background: white;
  box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
  transition: all 0.2s ease;
}

.analysis-tool:hover {
  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
  transform: translateY(-1px);
}

.tool-header h3 {
  font-size: 1.25rem;
  font-weight: 600;
  margin-bottom: 0.5rem;
}

.tool-header p {
  color: #6b7280;
  font-size: 0.875rem;
  margin-bottom: 1rem;
}

.analysis-results {
  margin-top: 2rem;
}

/* éŸ¿æ‡‰å¼è¨­è¨ˆ */
@media (max-width: 768px) {
  .ai-analysis-tab {
    padding: 1rem;
  }
  
  .tool-grid {
    grid-template-columns: 1fr;
    gap: 1rem;
  }
}
```

---

## ğŸ”§ å¾Œç«¯å¯¦ä½œè¦æ ¼

### API ç«¯é»è¨­è¨ˆ

#### è·¯ç”±çµæ§‹
```python
# src/coaching_assistant/api/v1/ai_analysis.py
from fastapi import APIRouter, Depends, HTTPException
from typing import Dict, Any
from .models import SummaryRequest, FeedbackRequest

router = APIRouter(prefix="/ai-analysis", tags=["AI Analysis"])

@router.post("/summary")
async def generate_summary(
    request: SummaryRequest,
    current_user: User = Depends(get_current_user)
) -> Dict[str, Any]:
    """ç”Ÿæˆæœƒè«‡æ‘˜è¦"""
    pass

@router.post("/feedback")  
async def generate_feedback(
    request: FeedbackRequest,
    current_user: User = Depends(get_current_user)
) -> Dict[str, Any]:
    """ç”Ÿæˆæœƒè«‡å›é¥‹"""
    pass
```

#### è«‹æ±‚/å›æ‡‰æ¨¡å‹
```python
# src/coaching_assistant/api/v1/models/ai_analysis.py
from pydantic import BaseModel
from typing import List, Optional, Dict, Any

class SummaryRequest(BaseModel):
    session_id: str
    content: str
    language: str = "zh-TW"
    format: str = "structured"  # structured, narrative

class SummaryResponse(BaseModel):
    session_id: str
    summary: Dict[str, Any]
    generated_at: str
    processing_time: float

class FeedbackRequest(BaseModel):
    session_id: str
    content: str
    language: str = "zh-TW"
    focus: str = "learning_support"  # learning_support, skill_development

class FeedbackResponse(BaseModel):
    session_id: str
    feedback: Dict[str, Any]
    generated_at: str
    processing_time: float
```

### LLM æœå‹™å±¤

#### AI åˆ†ææœå‹™
```python
# src/coaching_assistant/services/ai_analysis.py
import asyncio
import time
from typing import Dict, Any, Optional
from ..core.config import settings
from .lemur_service import LeMURService
from .openai_service import OpenAIService

class AIAnalysisService:
    def __init__(self):
        self.lemur_service = LeMURService()
        self.openai_service = OpenAIService()  # å‚™ç”¨æœå‹™
        
    async def generate_summary(
        self, 
        content: str, 
        language: str = "zh-TW",
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæœƒè«‡æ‘˜è¦"""
        start_time = time.time()
        
        try:
            # å„ªå…ˆä½¿ç”¨ LeMUR
            prompt = self._build_summary_prompt(content, language)
            result = await self.lemur_service.process(prompt)
            
            summary = self._parse_summary_result(result)
            
        except Exception as e:
            # é™ç´šåˆ° OpenAI
            logger.warning(f"LeMUR failed, falling back to OpenAI: {e}")
            result = await self.openai_service.generate_summary(content, language)
            summary = result
            
        processing_time = time.time() - start_time
        
        # è¨˜éŒ„åˆ†ææ­·å²
        if session_id:
            await self._save_analysis_history(
                session_id, "summary", summary, processing_time
            )
            
        return {
            "summary": summary,
            "processing_time": processing_time,
            "provider": "lemur" if "lemur" in locals() else "openai"
        }

    async def generate_feedback(
        self,
        content: str,
        language: str = "zh-TW", 
        focus: str = "learning_support",
        session_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """ç”Ÿæˆæœƒè«‡å›é¥‹"""
        start_time = time.time()
        
        try:
            prompt = self._build_feedback_prompt(content, language, focus)
            result = await self.lemur_service.process(prompt)
            feedback = self._parse_feedback_result(result)
            
        except Exception as e:
            logger.warning(f"LeMUR failed, falling back to OpenAI: {e}")
            result = await self.openai_service.generate_feedback(content, language, focus)
            feedback = result
            
        processing_time = time.time() - start_time
        
        if session_id:
            await self._save_analysis_history(
                session_id, "feedback", feedback, processing_time
            )
            
        return {
            "feedback": feedback,
            "processing_time": processing_time,
            "provider": "lemur" if "lemur" in locals() else "openai"
        }
```

### Prompt è¨­è¨ˆ

#### æ‘˜è¦ç”Ÿæˆ Prompt
```python
def _build_summary_prompt(self, content: str, language: str) -> str:
    """æ§‹å»ºæ‘˜è¦ç”Ÿæˆ prompt"""
    
    if language == "zh-TW":
        prompt = f"""
è«‹åˆ†æä»¥ä¸‹æ•™ç·´æœƒè«‡é€å­—ç¨¿ï¼Œä¸¦ç”Ÿæˆçµæ§‹åŒ–æ‘˜è¦ã€‚

é€å­—ç¨¿å…§å®¹ï¼š
{content}

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹çµæ§‹ï¼š
{{
  "session_overview": {{
    "duration_estimate": "é ä¼°æ™‚é•·",
    "main_topic": "ä¸»è¦è­°é¡Œ",
    "session_mood": "æœƒè«‡æ°›åœ"
  }},
  "key_topics": [
    {{
      "topic": "è­°é¡Œåç¨±",
      "discussion_points": ["è¨è«–è¦é»1", "è¨è«–è¦é»2"],
      "insights": "é—œéµæ´å¯Ÿ"
    }}
  ],
  "progress_indicators": [
    {{
      "area": "é€²å±•é ˜åŸŸ",
      "observation": "è§€å¯Ÿåˆ°çš„é€²å±•",
      "evidence": "æ”¯æŒè­‰æ“š"
    }}
  ],
  "action_items": [
    {{
      "action": "è¡Œå‹•é …ç›®",
      "owner": "è² è²¬äººï¼ˆæ•™ç·´/å®¢æˆ¶ï¼‰",
      "timeline": "æ™‚é–“æ¡†æ¶"
    }}
  ],
  "coaching_notes": [
    "é‡è¦çš„æ•™ç·´ç­†è¨˜æˆ–è§€å¯Ÿ"
  ]
}}

è«‹ç¢ºä¿ï¼š
1. æ‘˜è¦å®¢è§€æº–ç¢ºï¼Œé¿å…ä¸»è§€åˆ¤æ–·
2. é‡é»é—œæ³¨å®¢æˆ¶çš„éœ€æ±‚å’Œç›®æ¨™
3. è­˜åˆ¥å…·é«”çš„è¡Œå‹•é …ç›®å’Œä¸‹ä¸€æ­¥
4. ä¿æŒå°ˆæ¥­å’Œå»ºè¨­æ€§çš„èªèª¿
"""
    else:  # English
        prompt = f"""
Please analyze the following coaching session transcript and generate a structured summary.

Transcript content:
{content}

Please respond in JSON format with the following structure:
{{
  "session_overview": {{
    "duration_estimate": "estimated duration",
    "main_topic": "main topic discussed",
    "session_mood": "overall session atmosphere"
  }},
  "key_topics": [
    {{
      "topic": "topic name",
      "discussion_points": ["point 1", "point 2"],
      "insights": "key insights"
    }}
  ],
  "progress_indicators": [
    {{
      "area": "progress area",
      "observation": "observed progress",
      "evidence": "supporting evidence"
    }}
  ],
  "action_items": [
    {{
      "action": "action item",
      "owner": "responsible party (coach/client)",
      "timeline": "timeframe"
    }}
  ],
  "coaching_notes": [
    "important coaching notes or observations"
  ]
}}

Please ensure:
1. Summary is objective and accurate
2. Focus on client needs and goals
3. Identify specific action items and next steps
4. Maintain professional and constructive tone
"""
    
    return prompt
```

#### å›é¥‹ç”Ÿæˆ Prompt
```python
def _build_feedback_prompt(self, content: str, language: str, focus: str) -> str:
    """æ§‹å»ºå›é¥‹ç”Ÿæˆ prompt"""
    
    if language == "zh-TW":
        prompt = f"""
è«‹åˆ†æä»¥ä¸‹æ•™ç·´æœƒè«‡é€å­—ç¨¿ï¼Œä¸¦æä¾›å­¸ç¿’å°å‘çš„å›é¥‹å»ºè­°ã€‚

é€å­—ç¨¿å…§å®¹ï¼š
{content}

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹çµæ§‹ï¼š
{{
  "strengths_observed": [
    {{
      "skill_area": "æŠ€èƒ½é ˜åŸŸ",
      "observation": "è§€å¯Ÿåˆ°çš„å„ªå‹¢",
      "examples": ["å…·é«”ä¾‹å­"],
      "impact": "å°æœƒè«‡çš„æ­£é¢å½±éŸ¿"
    }}
  ],
  "learning_opportunities": [
    {{
      "area": "å­¸ç¿’é ˜åŸŸ",
      "suggestion": "å»ºè­°",
      "techniques": ["å¯å˜—è©¦çš„æŠ€å·§"],
      "resources": ["å­¸ç¿’è³‡æºå»ºè­°"]
    }}
  ],
  "questioning_techniques": {{
    "effective_questions": ["æœ‰æ•ˆçš„å•é¡Œç¯„ä¾‹"],
    "suggested_improvements": ["å•å¥æ”¹å–„å»ºè­°"],
    "alternative_approaches": ["æ›¿ä»£æ–¹æ³•"]
  }},
  "communication_insights": {{
    "listening_patterns": "å‚¾è½æ¨¡å¼è§€å¯Ÿ",
    "response_style": "å›æ‡‰é¢¨æ ¼åˆ†æ",
    "suggestions": ["æºé€šæ”¹å–„å»ºè­°"]
  }},
  "next_session_considerations": [
    "ä¸‹æ¬¡æœƒè«‡çš„è€ƒæ…®è¦é»"
  ]
}}

é‡è¦åŸå‰‡ï¼š
1. é¿å…è©•åˆ†æˆ–ç­‰ç´šè©•ä¼°
2. å°ˆæ³¨æ–¼å­¸ç¿’å’Œç™¼å±•æ©Ÿæœƒ
3. æä¾›å…·é«”å¯è¡Œçš„å»ºè­°
4. ä¿æŒé¼“å‹µå’Œæ”¯æŒçš„èªèª¿
5. å¼·èª¿æŠ€èƒ½æå‡è€Œéç¼ºé»æŒ‡æ­£
"""
    else:  # English
        prompt = f"""
Please analyze the following coaching session transcript and provide learning-oriented feedback.

Transcript content:
{content}

Please respond in JSON format with the following structure:
{{
  "strengths_observed": [
    {{
      "skill_area": "skill area",
      "observation": "observed strength",
      "examples": ["specific examples"],
      "impact": "positive impact on session"
    }}
  ],
  "learning_opportunities": [
    {{
      "area": "learning area",
      "suggestion": "suggestion",
      "techniques": ["techniques to try"],
      "resources": ["learning resource suggestions"]
    }}
  ],
  "questioning_techniques": {{
    "effective_questions": ["examples of effective questions"],
    "suggested_improvements": ["question improvement suggestions"],
    "alternative_approaches": ["alternative approaches"]
  }},
  "communication_insights": {{
    "listening_patterns": "listening pattern observations",
    "response_style": "response style analysis",
    "suggestions": ["communication improvement suggestions"]
  }},
  "next_session_considerations": [
    "considerations for next session"
  ]
}}

Important principles:
1. Avoid scoring or grading assessments
2. Focus on learning and development opportunities
3. Provide specific, actionable suggestions
4. Maintain encouraging and supportive tone
5. Emphasize skill enhancement rather than deficit correction
"""
    
    return prompt
```

---

## ğŸ—„ï¸ è³‡æ–™æ¨¡å‹

### åˆ†ææ­·å²è¡¨
```sql
-- æ–°å¢ AI åˆ†ææ­·å²è¡¨
CREATE TABLE ai_analysis_history (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID REFERENCES session(id) ON DELETE CASCADE,
    user_id UUID REFERENCES "user"(id) ON DELETE CASCADE,
    analysis_type VARCHAR(50) NOT NULL, -- 'summary', 'feedback'
    analysis_result JSONB NOT NULL,
    provider VARCHAR(50) NOT NULL, -- 'lemur', 'openai'
    processing_time FLOAT NOT NULL,
    created_at TIMESTAMP DEFAULT NOW(),
    
    INDEX idx_ai_analysis_session (session_id),
    INDEX idx_ai_analysis_user (user_id),
    INDEX idx_ai_analysis_type (analysis_type)
);
```

### é…ç½®ç®¡ç†
```python
# src/coaching_assistant/core/config.py
class Settings(BaseSettings):
    # AI Analysis settings
    AI_ANALYSIS_ENABLED: bool = True
    AI_ANALYSIS_TIMEOUT: int = 30  # seconds
    AI_ANALYSIS_MAX_RETRIES: int = 2
    
    # LeMUR settings
    LEMUR_API_KEY: str
    LEMUR_BASE_URL: str = "https://api.assemblyai.com"
    
    # OpenAI backup settings
    OPENAI_API_KEY: Optional[str] = None
    OPENAI_MODEL: str = "gpt-4"
```

---

## ğŸ”’ å®‰å…¨æ€§è€ƒé‡

### è³‡æ–™ä¿è­·
```python
# è³‡æ–™è„«æ•è™•ç†
def sanitize_transcript_for_ai(content: str) -> str:
    """ç§»é™¤æ•æ„Ÿè³‡è¨Šå¾Œå†é€çµ¦ AI åˆ†æ"""
    # ç§»é™¤é›»è©±è™Ÿç¢¼
    content = re.sub(r'\b\d{4}-\d{6}\b', '[é›»è©±]', content)
    # ç§»é™¤èº«åˆ†è­‰è™Ÿ
    content = re.sub(r'\b[A-Z]\d{9}\b', '[èº«åˆ†è­‰]', content)
    # ç§»é™¤ä¿¡ç”¨å¡è™Ÿ
    content = re.sub(r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b', '[ä¿¡ç”¨å¡]', content)
    return content

# æ¬Šé™æª¢æŸ¥
async def verify_analysis_permission(session_id: str, user_id: str) -> bool:
    """ç¢ºèªç”¨æˆ¶æœ‰æ¬Šé™åˆ†æè©²æœƒè«‡"""
    session = await get_session_by_id(session_id)
    return session.user_id == user_id
```

### è²»ç”¨æ§åˆ¶
```python
# AI ä½¿ç”¨é‡æ§åˆ¶
class AIUsageTracker:
    async def check_usage_limit(self, user_id: str) -> bool:
        """æª¢æŸ¥ç”¨æˆ¶ AI åˆ†æä½¿ç”¨é‡"""
        monthly_usage = await get_monthly_ai_usage(user_id)
        user_plan = await get_user_plan(user_id)
        
        limits = {
            "free": 5,      # å…è²»ç‰ˆæ¯æœˆ 5 æ¬¡
            "student": 10,   # å­¸ç”Ÿç‰ˆæ¯æœˆ 10 æ¬¡  
            "pro": 50,      # å°ˆæ¥­ç‰ˆæ¯æœˆ 50 æ¬¡
        }
        
        return monthly_usage < limits.get(user_plan, 0)
```

---

## ğŸ“Š æ€§èƒ½å„ªåŒ–

### å¿«å–ç­–ç•¥
```python
# çµæœå¿«å–
from functools import lru_cache
from typing import Optional

class AIAnalysisService:
    def __init__(self):
        self.result_cache = {}
        
    async def generate_summary_cached(
        self, 
        content: str, 
        language: str = "zh-TW"
    ) -> Dict[str, Any]:
        """å¸¶å¿«å–çš„æ‘˜è¦ç”Ÿæˆ"""
        cache_key = f"summary:{hash(content)}:{language}"
        
        if cache_key in self.result_cache:
            return self.result_cache[cache_key]
            
        result = await self.generate_summary(content, language)
        self.result_cache[cache_key] = result
        
        return result
```

### éåŒæ­¥è™•ç†
```python
# èƒŒæ™¯ä»»å‹™è™•ç†
from celery import Celery

@celery.task
def generate_analysis_background(session_id: str, analysis_type: str):
    """èƒŒæ™¯ç”Ÿæˆåˆ†æçµæœ"""
    # é•·æ™‚é–“åˆ†æä»»å‹™å¯ä»¥åœ¨èƒŒæ™¯åŸ·è¡Œ
    # å®Œæˆå¾Œé€šé WebSocket æˆ–è¼ªè©¢é€šçŸ¥å‰ç«¯
    pass
```

---

## ğŸ§ª æ¸¬è©¦ç­–ç•¥

### å–®å…ƒæ¸¬è©¦
```python
# tests/unit/services/test_ai_analysis.py
import pytest
from unittest.mock import AsyncMock, patch
from coaching_assistant.services.ai_analysis import AIAnalysisService

class TestAIAnalysisService:
    @pytest.fixture
    def ai_service(self):
        return AIAnalysisService()
    
    @pytest.mark.asyncio
    async def test_generate_summary(self, ai_service):
        """æ¸¬è©¦æ‘˜è¦ç”ŸæˆåŠŸèƒ½"""
        content = "æ•™ç·´: ä½ ä»Šå¤©éå¾—å¦‚ä½•ï¼Ÿ\nå®¢æˆ¶: å¾ˆå¥½ï¼Œè¬è¬ã€‚"
        
        with patch.object(ai_service.lemur_service, 'process') as mock_process:
            mock_process.return_value = {"summary": "test summary"}
            
            result = await ai_service.generate_summary(content)
            
            assert "summary" in result
            assert "processing_time" in result
            mock_process.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_generate_feedback(self, ai_service):
        """æ¸¬è©¦å›é¥‹ç”ŸæˆåŠŸèƒ½"""
        content = "æ•™ç·´: ä½ ä»Šå¤©éå¾—å¦‚ä½•ï¼Ÿ\nå®¢æˆ¶: å¾ˆå¥½ï¼Œè¬è¬ã€‚"
        
        result = await ai_service.generate_feedback(content)
        
        assert "feedback" in result
        assert "processing_time" in result
```

### æ•´åˆæ¸¬è©¦
```python
# tests/integration/api/test_ai_analysis.py
import pytest
from httpx import AsyncClient

@pytest.mark.asyncio
async def test_summary_api_endpoint(client: AsyncClient, auth_headers):
    """æ¸¬è©¦æ‘˜è¦ API ç«¯é»"""
    payload = {
        "session_id": "test-session-id",
        "content": "æ¸¬è©¦é€å­—ç¨¿å…§å®¹",
        "language": "zh-TW"
    }
    
    response = await client.post(
        "/ai-analysis/summary",
        json=payload,
        headers=auth_headers
    )
    
    assert response.status_code == 200
    data = response.json()
    assert "summary" in data
    assert "processing_time" in data
```

---

## ğŸš€ éƒ¨ç½²é…ç½®

### ç’°å¢ƒè®Šæ•¸
```bash
# .env
AI_ANALYSIS_ENABLED=true
AI_ANALYSIS_TIMEOUT=30
LEMUR_API_KEY=your_assemblyai_api_key
OPENAI_API_KEY=your_openai_api_key_optional
```

### Docker é…ç½®
```dockerfile
# Dockerfile æ›´æ–°
# ç¢ºä¿ AI åˆ†æç›¸é—œä¾è³´å·²å®‰è£
RUN pip install openai assemblyai
```

### ç›£æ§è¨­ç½®
```python
# åˆ†ææ€§èƒ½ç›£æ§
import time
from prometheus_client import Counter, Histogram

ai_analysis_requests = Counter('ai_analysis_requests_total', 'Total AI analysis requests', ['type', 'status'])
ai_analysis_duration = Histogram('ai_analysis_duration_seconds', 'AI analysis duration', ['type'])

async def generate_summary_with_metrics(self, content: str, language: str = "zh-TW"):
    start_time = time.time()
    
    try:
        result = await self.generate_summary(content, language)
        ai_analysis_requests.labels(type='summary', status='success').inc()
        return result
    except Exception as e:
        ai_analysis_requests.labels(type='summary', status='error').inc()
        raise
    finally:
        duration = time.time() - start_time
        ai_analysis_duration.labels(type='summary').observe(duration)
```

---

## ğŸ“‹ äº¤ä»˜æª¢æŸ¥æ¸…å–®

### å‰ç«¯é–‹ç™¼
- [ ] AI åˆ†æ Tab çµ„ä»¶å®Œæˆ
- [ ] æ‘˜è¦ç”Ÿæˆå™¨çµ„ä»¶å®Œæˆ
- [ ] å›é¥‹ç”Ÿæˆå™¨çµ„ä»¶å®Œæˆ
- [ ] è¼‰å…¥å’ŒéŒ¯èª¤ç‹€æ…‹è™•ç†
- [ ] éŸ¿æ‡‰å¼è¨­è¨ˆé©é…
- [ ] i18n ç¿»è­¯å®Œæ•´

### å¾Œç«¯é–‹ç™¼  
- [ ] API ç«¯é»å¯¦ä½œå®Œæˆ
- [ ] LLM æœå‹™å±¤æ•´åˆ
- [ ] Prompt è¨­è¨ˆå’Œå„ªåŒ–
- [ ] è³‡æ–™åº«è¡¨å»ºç«‹
- [ ] æ¬Šé™å’Œå®‰å…¨æª¢æŸ¥
- [ ] éŒ¯èª¤è™•ç†å’Œé™ç´šæ©Ÿåˆ¶

### æ¸¬è©¦èˆ‡å“è³ª
- [ ] å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ â‰¥ 90%
- [ ] æ•´åˆæ¸¬è©¦å®Œæˆ
- [ ] æ€§èƒ½æ¸¬è©¦é€šé
- [ ] å®‰å…¨æ¸¬è©¦å®Œæˆ
- [ ] ç”¨æˆ¶é©—æ”¶æ¸¬è©¦

### éƒ¨ç½²èˆ‡ç›£æ§
- [ ] ç’°å¢ƒé…ç½®å®Œæˆ
- [ ] ç›£æ§æŒ‡æ¨™è¨­ç½®
- [ ] æ—¥èªŒè¨˜éŒ„å®Œæ•´
- [ ] å‚™ä»½å’Œæ¢å¾©æ©Ÿåˆ¶
- [ ] æ–‡æª”æ›´æ–°å®Œæˆ

---

*æ­¤è¦æ ¼æ–‡æª”å°‡éš¨é–‹ç™¼é€²åº¦æŒçºŒæ›´æ–°ï¼Œç¢ºä¿å¯¦ä½œç¬¦åˆè¨­è¨ˆè¦æ±‚ã€‚*